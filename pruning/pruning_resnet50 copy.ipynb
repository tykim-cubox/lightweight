{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiteam/miniconda3/envs/loader/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently available device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"currently available device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "      transforms.RandomCrop(32, padding = 4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "     ]\n",
    "     )\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "     ]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "        root = './data', train = True,\n",
    "        download = True, transform = transform_train\n",
    "        )\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "        root = './data', train = False,\n",
    "        download = True, transform = transform_test\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size = batch_size,\n",
    "        shuffle = True, num_workers=16, pin_memory=True\n",
    "        )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size = batch_size,\n",
    "        shuffle = False , num_workers=16, pin_memory=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "from torchvision.models import ResNet50_Weights, resnet50\n",
    "standard_model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.models import quantization\n",
    "# quantized_model = quantization.resnet50(weights=quantization.ResNet50_QuantizedWeights.IMAGENET1K_FBGEMM_V2, \n",
    "#                                         quantize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = standard_model.fc.in_features\n",
    "\n",
    "standard_model.fc = nn.Linear(in_features = num_ftrs, out_features = 10)\n",
    "\n",
    "standard_model.conv1 = torch.nn.Conv2d(\n",
    "    in_channels = 3, out_channels = 64,\n",
    "    kernel_size = (3, 3), stride = (1, 1),\n",
    "    padding = (1, 1), bias = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruning 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_parameters(model):\n",
    "    \n",
    "    for module_name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            try:\n",
    "                prune.remove(module, \"weight\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                prune.remove(module, \"bias\")\n",
    "            except:\n",
    "                pass\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "            try:\n",
    "                prune.remove(module, \"weight\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                prune.remove(module, \"bias\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_module_sparsity(module, weight=True, bias=False, use_mask=False):\n",
    "\n",
    "    num_zeros = 0\n",
    "    num_elements = 0\n",
    "\n",
    "    if use_mask == True:\n",
    "        for buffer_name, buffer in module.named_buffers():\n",
    "            if \"weight_mask\" in buffer_name and weight == True:\n",
    "                num_zeros += torch.sum(buffer == 0).item()\n",
    "                num_elements += buffer.nelement()\n",
    "            if \"bias_mask\" in buffer_name and bias == True:\n",
    "                num_zeros += torch.sum(buffer == 0).item()\n",
    "                num_elements += buffer.nelement()\n",
    "    else:\n",
    "        for param_name, param in module.named_parameters():\n",
    "            if \"weight\" in param_name and weight == True:\n",
    "                num_zeros += torch.sum(param == 0).item()\n",
    "                num_elements += param.nelement()\n",
    "            if \"bias\" in param_name and bias == True:\n",
    "                num_zeros += torch.sum(param == 0).item()\n",
    "                num_elements += param.nelement()\n",
    "\n",
    "    sparsity = num_zeros / num_elements\n",
    "\n",
    "    return num_zeros, num_elements, sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_global_sparsity(\n",
    "    model, weight = True,\n",
    "    bias = False, conv2d_use_mask = False,\n",
    "    linear_use_mask = False):\n",
    "\n",
    "    num_zeros = 0\n",
    "    num_elements = 0\n",
    "\n",
    "    for module_name, module in model.named_modules():\n",
    "\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "\n",
    "            module_num_zeros, module_num_elements, _ = measure_module_sparsity(\n",
    "                module, weight=weight, bias=bias, use_mask=conv2d_use_mask)\n",
    "            num_zeros += module_num_zeros\n",
    "            num_elements += module_num_elements\n",
    "\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "\n",
    "            module_num_zeros, module_num_elements, _ = measure_module_sparsity(\n",
    "                module, weight=weight, bias=bias, use_mask=linear_use_mask)\n",
    "            num_zeros += module_num_zeros\n",
    "            num_elements += module_num_elements\n",
    "\n",
    "    sparsity = num_zeros / num_elements\n",
    "\n",
    "    return num_zeros, num_elements, sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_regularization_strength = 0\n",
    "l2_regularization_strength = 1e-4\n",
    "learning_rate = 0.01\n",
    "learning_rate_decay = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, criterion = None):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        if criterion is not None:\n",
    "            loss = criterion(outputs, labels).item()\n",
    "        else:\n",
    "            loss = 0\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    eval_loss = running_loss / len(test_loader.dataset)\n",
    "    eval_accuracy = running_corrects / len(test_loader.dataset)\n",
    "\n",
    "    return eval_loss, eval_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_train_model(model, train_loader, test_loader, device, l1_regularization_strength = 0,\n",
    "                l2_regularization_strength = 1e-4, learning_rate = 1e-1, num_epochs = 20):\n",
    "\n",
    "    # The training configurations were not carefully selected.\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # It seems that SGD optimizer is better than Adam optimizer for ResNet18 training on CIFAR10-\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), lr = learning_rate,\n",
    "        momentum = 0.9, weight_decay = l2_regularization_strength\n",
    "    )\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    \n",
    "    # Define learning rate scheduler-\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        # optimizer, milestones = [100, 150],\n",
    "        optimizer, milestones = [8, 15],\n",
    "        gamma = 0.1, last_epoch = -1)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)\n",
    "    \n",
    "\n",
    "    # Evaluation-\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = evaluate_model(\n",
    "        model = model, test_loader = test_loader,\n",
    "        device = device, criterion = criterion)\n",
    "    \n",
    "    print(f\"Pre fine-tuning: val_loss = {eval_loss:.3f} & val_accuracy = {eval_accuracy * 100:.3f}%\")\n",
    "    # print(\"Epoch: {:03d} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(0, eval_loss, eval_accuracy))\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            l1_reg = torch.tensor(0.).to(device)\n",
    "            for module in model.modules():\n",
    "                mask = None\n",
    "                weight = None\n",
    "                for name, buffer in module.named_buffers():\n",
    "                    if name == \"weight_mask\":\n",
    "                        mask = buffer\n",
    "                for name, param in module.named_parameters():\n",
    "                    if name == \"weight_orig\":\n",
    "                        weight = param\n",
    "                # We usually only want to introduce sparsity to weights and prune weights.\n",
    "                # Do the same for bias if necessary.\n",
    "                if mask is not None and weight is not None:\n",
    "                    l1_reg += torch.norm(mask * weight, 1)\n",
    "\n",
    "            loss += l1_regularization_strength * l1_reg\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_accuracy = running_corrects / len(train_loader.dataset)\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        eval_loss, eval_accuracy = evaluate_model(\n",
    "            model = model, test_loader = test_loader,\n",
    "            device = device, criterion = criterion)\n",
    "\n",
    "        # Set learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        '''\n",
    "        print(\n",
    "            \"Epoch: {:03d} Train Loss: {:.3f} Train Acc: {:.3f} Eval Loss: {:.3f} Eval Acc: {:.3f}\"\n",
    "            .format(epoch + 1, train_loss, train_accuracy, eval_loss,\n",
    "                    eval_accuracy))\n",
    "        '''\n",
    "        print(f\"epoch = {epoch + 1} loss = {train_loss:.3f}, accuracy = {train_accuracy * 100:.3f}%, val_loss = {eval_loss:.3f}, val_accuracy = {eval_accuracy * 100:.3f}% & LR: {optimizer.param_groups[0]['lr']:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_pruning_finetuning(\n",
    "    model, train_loader, test_loader, device,\n",
    "    learning_rate, l1_regularization_strength,\n",
    "    l2_regularization_strength, learning_rate_decay = 0.1,\n",
    "    conv2d_prune_amount = 0.2, linear_prune_amount = 0.1,\n",
    "    num_iterations = 10, num_epochs_per_iteration = 10,\n",
    "    model_filename_prefix = \"pruned_model\", model_dir = \"saved_models\",\n",
    "    grouped_pruning = False):\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        print(\"\\nPruning and Finetuning {}/{}\".format(i + 1, num_iterations))\n",
    "\n",
    "        print(\"Pruning...\")\n",
    "\n",
    "\n",
    "        # NOTE: For global pruning, linear/dense layer can also be pruned!\n",
    "        if grouped_pruning == True:\n",
    "            # grouped_pruning -> Global pruning\n",
    "            parameters_to_prune = []\n",
    "            for module_name, module in model.named_modules():\n",
    "                if isinstance(module, torch.nn.Conv2d):\n",
    "                    parameters_to_prune.append((module, \"weight\"))\n",
    "                elif isinstance(module, torch.nn.Linear):\n",
    "                    parameters_to_prune.append((module, \"weight\"))\n",
    "        \n",
    "            # L1Unstructured - prune (currently unpruned) entries in a tensor by zeroing\n",
    "            # out the ones with the lowest absolute magnitude-\n",
    "            prune.global_unstructured(\n",
    "                parameters_to_prune,\n",
    "                pruning_method = prune.L1Unstructured,\n",
    "                amount = conv2d_prune_amount,\n",
    "            )\n",
    "        \n",
    "        # layer-wise pruning-\n",
    "        else:\n",
    "            for module_name, module in model.named_modules():\n",
    "                if isinstance(module, torch.nn.Conv2d):\n",
    "                    prune.l1_unstructured(\n",
    "                        module, name = \"weight\",\n",
    "                        amount = conv2d_prune_amount)\n",
    "                elif isinstance(module, torch.nn.Linear):\n",
    "                    prune.l1_unstructured(\n",
    "                        module, name = \"weight\",\n",
    "                        amount = linear_prune_amount)\n",
    "\n",
    "        # Compute validation accuracy just after pruning-\n",
    "        _, eval_accuracy = evaluate_model(\n",
    "            model = model, test_loader = test_loader,\n",
    "            device = device, criterion = None)\n",
    "\n",
    "    \n",
    "\n",
    "        # Compute global sparsity-\n",
    "        num_zeros, num_elements, sparsity = measure_global_sparsity(\n",
    "            model, weight = True,\n",
    "            bias = False, conv2d_use_mask = True,\n",
    "            linear_use_mask = False)\n",
    "        \n",
    "        print(f\"Global sparsity = {sparsity * 100:.3f}% & val_accuracy = {eval_accuracy * 100:.3f}%\")\n",
    "        # print(model.conv1._forward_pre_hooks)\n",
    "        \n",
    "        \n",
    "        print(\"\\nFine-tuning...\")\n",
    "        \n",
    "        fine_tuned_model = fine_tune_train_model(\n",
    "            model = model, train_loader = train_loader,\n",
    "            test_loader = test_loader, device = device,\n",
    "            l1_regularization_strength = l1_regularization_strength,\n",
    "            l2_regularization_strength = l2_regularization_strength,\n",
    "            # i -> current pruning round-\n",
    "            # learning_rate = learning_rate * (learning_rate_decay ** i),\n",
    "            learning_rate = learning_rate,\n",
    "            num_epochs = num_epochs_per_iteration)\n",
    "\n",
    "        _, eval_accuracy = evaluate_model(\n",
    "            model=model, test_loader = test_loader,\n",
    "            device = device, criterion = None)\n",
    "\n",
    "\n",
    "        num_zeros, num_elements, sparsity = measure_global_sparsity(\n",
    "            # model,\n",
    "            fine_tuned_model, weight = True,\n",
    "            bias = False, conv2d_use_mask = True,\n",
    "            linear_use_mask = False)\n",
    "\n",
    "        print(f\"Post fine-tuning: Global sparsity = {sparsity * 100:.3f}% & val_accuracy = {eval_accuracy * 100:.3f}%\")\n",
    "        model = remove_parameters(model = model)\n",
    "        '''\n",
    "        model_filename = \"{}_{}.pt\".format(model_filename_prefix, i + 1)\n",
    "        model_filepath = os.path.join(model_dir, model_filename)\n",
    "        save_model(model=model,\n",
    "                   model_dir=model_dir,\n",
    "                   model_filename=model_filename)\n",
    "        model = load_model(model=model,\n",
    "                           model_filepath=model_filepath,\n",
    "                           device=device)\n",
    "        '''\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, eval_accuracy = evaluate_model(\n",
    "    model = standard_model, test_loader=test_loader,\n",
    "    device = device, criterion = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity = 0.000% & val_accuracy = 10.810%\n"
     ]
    }
   ],
   "source": [
    "num_zeros, num_elements, sparsity = measure_global_sparsity(standard_model)\n",
    "print(f\"Global sparsity = {sparsity:.3f}% & val_accuracy = {eval_accuracy * 100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pruning and Finetuning 1/5\n",
      "Pruning...\n",
      "Global sparsity = 19.978% & val_accuracy = 10.920%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 2.384 & val_accuracy = 10.920%\n",
      "epoch = 1 loss = 1.211, accuracy = 56.496%, val_loss = 0.554, val_accuracy = 80.920% & LR: 0.0100\n",
      "epoch = 2 loss = 0.456, accuracy = 84.182%, val_loss = 0.356, val_accuracy = 87.510% & LR: 0.0100\n",
      "epoch = 3 loss = 0.296, accuracy = 89.768%, val_loss = 0.270, val_accuracy = 90.520% & LR: 0.0100\n",
      "epoch = 4 loss = 0.221, accuracy = 92.342%, val_loss = 0.245, val_accuracy = 91.770% & LR: 0.0100\n",
      "epoch = 5 loss = 0.175, accuracy = 93.984%, val_loss = 0.232, val_accuracy = 92.220% & LR: 0.0100\n",
      "epoch = 6 loss = 0.146, accuracy = 94.962%, val_loss = 0.230, val_accuracy = 92.470% & LR: 0.0100\n",
      "epoch = 7 loss = 0.122, accuracy = 95.712%, val_loss = 0.214, val_accuracy = 92.940% & LR: 0.0100\n",
      "Post fine-tuning: Global sparsity = 19.978% & val_accuracy = 92.940%\n",
      "\n",
      "Pruning and Finetuning 2/5\n",
      "Pruning...\n",
      "Global sparsity = 20.000% & val_accuracy = 92.940%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.214 & val_accuracy = 92.940%\n",
      "epoch = 1 loss = 0.104, accuracy = 96.364%, val_loss = 0.204, val_accuracy = 93.410% & LR: 0.0100\n",
      "epoch = 2 loss = 0.088, accuracy = 96.900%, val_loss = 0.206, val_accuracy = 93.270% & LR: 0.0100\n",
      "epoch = 3 loss = 0.080, accuracy = 97.222%, val_loss = 0.206, val_accuracy = 93.680% & LR: 0.0100\n",
      "epoch = 4 loss = 0.069, accuracy = 97.624%, val_loss = 0.202, val_accuracy = 93.890% & LR: 0.0100\n",
      "epoch = 5 loss = 0.058, accuracy = 98.028%, val_loss = 0.201, val_accuracy = 93.740% & LR: 0.0100\n",
      "epoch = 6 loss = 0.052, accuracy = 98.162%, val_loss = 0.212, val_accuracy = 93.910% & LR: 0.0100\n",
      "epoch = 7 loss = 0.044, accuracy = 98.408%, val_loss = 0.199, val_accuracy = 94.410% & LR: 0.0100\n",
      "Post fine-tuning: Global sparsity = 20.000% & val_accuracy = 94.410%\n",
      "\n",
      "Pruning and Finetuning 3/5\n",
      "Pruning...\n",
      "Global sparsity = 20.000% & val_accuracy = 94.410%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.199 & val_accuracy = 94.410%\n",
      "epoch = 1 loss = 0.045, accuracy = 98.472%, val_loss = 0.204, val_accuracy = 94.010% & LR: 0.0100\n",
      "epoch = 2 loss = 0.039, accuracy = 98.666%, val_loss = 0.208, val_accuracy = 94.110% & LR: 0.0100\n",
      "epoch = 3 loss = 0.037, accuracy = 98.714%, val_loss = 0.216, val_accuracy = 94.210% & LR: 0.0100\n",
      "epoch = 4 loss = 0.034, accuracy = 98.850%, val_loss = 0.207, val_accuracy = 94.410% & LR: 0.0100\n",
      "epoch = 5 loss = 0.027, accuracy = 99.086%, val_loss = 0.227, val_accuracy = 94.260% & LR: 0.0100\n",
      "epoch = 6 loss = 0.027, accuracy = 99.038%, val_loss = 0.219, val_accuracy = 94.180% & LR: 0.0100\n",
      "epoch = 7 loss = 0.024, accuracy = 99.220%, val_loss = 0.222, val_accuracy = 94.570% & LR: 0.0100\n",
      "Post fine-tuning: Global sparsity = 20.000% & val_accuracy = 94.570%\n",
      "\n",
      "Pruning and Finetuning 4/5\n",
      "Pruning...\n",
      "Global sparsity = 20.000% & val_accuracy = 94.570%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.222 & val_accuracy = 94.570%\n",
      "epoch = 1 loss = 0.022, accuracy = 99.256%, val_loss = 0.220, val_accuracy = 94.420% & LR: 0.0100\n",
      "epoch = 2 loss = 0.022, accuracy = 99.236%, val_loss = 0.216, val_accuracy = 94.560% & LR: 0.0100\n",
      "epoch = 3 loss = 0.021, accuracy = 99.300%, val_loss = 0.223, val_accuracy = 94.510% & LR: 0.0100\n",
      "epoch = 4 loss = 0.019, accuracy = 99.332%, val_loss = 0.218, val_accuracy = 94.700% & LR: 0.0100\n",
      "epoch = 5 loss = 0.018, accuracy = 99.412%, val_loss = 0.217, val_accuracy = 94.700% & LR: 0.0100\n",
      "epoch = 6 loss = 0.017, accuracy = 99.428%, val_loss = 0.215, val_accuracy = 94.510% & LR: 0.0100\n",
      "epoch = 7 loss = 0.016, accuracy = 99.476%, val_loss = 0.213, val_accuracy = 94.970% & LR: 0.0100\n",
      "Post fine-tuning: Global sparsity = 20.000% & val_accuracy = 94.970%\n",
      "\n",
      "Pruning and Finetuning 5/5\n",
      "Pruning...\n",
      "Global sparsity = 20.000% & val_accuracy = 94.970%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.213 & val_accuracy = 94.970%\n",
      "epoch = 1 loss = 0.014, accuracy = 99.556%, val_loss = 0.225, val_accuracy = 94.720% & LR: 0.0100\n",
      "epoch = 2 loss = 0.015, accuracy = 99.472%, val_loss = 0.227, val_accuracy = 94.860% & LR: 0.0100\n",
      "epoch = 3 loss = 0.014, accuracy = 99.526%, val_loss = 0.226, val_accuracy = 94.840% & LR: 0.0100\n",
      "epoch = 4 loss = 0.011, accuracy = 99.622%, val_loss = 0.220, val_accuracy = 94.910% & LR: 0.0100\n",
      "epoch = 5 loss = 0.010, accuracy = 99.666%, val_loss = 0.236, val_accuracy = 94.610% & LR: 0.0100\n",
      "epoch = 6 loss = 0.013, accuracy = 99.578%, val_loss = 0.243, val_accuracy = 94.650% & LR: 0.0100\n",
      "epoch = 7 loss = 0.012, accuracy = 99.618%, val_loss = 0.230, val_accuracy = 94.960% & LR: 0.0100\n",
      "Post fine-tuning: Global sparsity = 20.000% & val_accuracy = 94.960%\n"
     ]
    }
   ],
   "source": [
    "pruned_model = copy.deepcopy(standard_model)\n",
    "\n",
    "\n",
    "# Prune and fine-tune trained model-\n",
    "'''\n",
    "num_iterations - number of pruning iterations/rounds\n",
    "num_epochs_per_iteration - number of fine-tuning rounds\n",
    "'''\n",
    "pruned_model = iterative_pruning_finetuning(\n",
    "        model = pruned_model, train_loader = train_loader,\n",
    "        test_loader = test_loader, device = device,\n",
    "        learning_rate = learning_rate, learning_rate_decay = learning_rate_decay,\n",
    "        l1_regularization_strength = l1_regularization_strength, l2_regularization_strength = l2_regularization_strength,\n",
    "        conv2d_prune_amount = 0.2, linear_prune_amount = 0.1,\n",
    "        num_iterations = 5, num_epochs_per_iteration = 7,\n",
    "        grouped_pruning = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity = 0.200 & val_accuracy = 0.950\n"
     ]
    }
   ],
   "source": [
    "final_model = remove_parameters(model = pruned_model)\n",
    "\n",
    "_, eval_accuracy = evaluate_model(\n",
    "    model = pruned_model, test_loader = test_loader,\n",
    "    device = device, criterion = None\n",
    ")\n",
    "\n",
    "\n",
    "num_zeros, num_elements, sparsity = measure_global_sparsity(final_model)\n",
    "\n",
    "\n",
    "print(f\"Global sparsity = {sparsity:.3f} & val_accuracy = {eval_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(final_model.state_dict(), f\"./ResNet50_trained_sparsity-{sparsity * 100:.3f}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.40 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2f MB\" %(os.path.getsize(\"/home/aiteam/tykim/scratch/lightweight/pruning/ResNet50_trained_sparsity-20.000.pth\")/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102.54 MB\n"
     ]
    }
   ],
   "source": [
    "standard_model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "def print_model_size(mdl):\n",
    "    torch.save(mdl.state_dict(), \"tmp.pt\")\n",
    "    print(\"%.2f MB\" %(os.path.getsize(\"tmp.pt\")/1e6))\n",
    "    os.remove('tmp.pt')\n",
    "    \n",
    "print_model_size(standard_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('loader')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a254999b829cf7a75923305dbce36972a67b91fdc16edd342b076b25e04d6382"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
